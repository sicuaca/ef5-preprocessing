{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Download SCAMPR through Amazon S3"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "158a4736d707baf2"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-07T05:00:51.370003500Z",
     "start_time": "2025-09-07T05:00:50.000072600Z"
    }
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "# import rioxarray\n",
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from datetime import timezone, datetime, timedelta\n",
    "from pandas import date_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "datelist = date_range(start='2025-02-11', end='2025-08-28', freq='h')\n",
    "\n",
    "for dtime in datelist:\n",
    "    print(\"Processing:\", dtime)\n",
    "    # Inisialisasi client S3 tanpa autentikasi (karena bucket public)\n",
    "    s3 = boto3.client('s3', config=boto3.session.Config(signature_version=UNSIGNED))\n",
    "    \n",
    "    bucket_name = \"noaa-enterprise-rainrate-pds\"\n",
    "    prefix = f\"BLEND/RainRate-Blend-INST/{dtime:%Y}/{dtime:%m}/{dtime:%d}/{dtime:%H}/\"\n",
    "    \n",
    "    # Ambil list objek\n",
    "    response = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
    "    objects = response.get(\"Contents\", [])\n",
    "    filtered = [obj for obj in objects if \"GLB-5\" in obj[\"Key\"]]\n",
    "    for latest_object in filtered:\n",
    "        local_dir_nc = \"G:/SCAMPR/nc\"\n",
    "        local_filename_nc = f\"{local_dir_nc}/{latest_object['Key'].split('/')[-1]}\"\n",
    "        s3.download_file(bucket_name, latest_object[\"Key\"], local_filename_nc)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fddac0961f4320e0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Clip and Convert to GeoTIFF"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8860ebb64e5fd6ab"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import rioxarray"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45093cbf64548fd2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nc_dir = \"G:/SCAMPR/nc\"\n",
    "filelist = os.listdir(nc_dir)\n",
    "domain = (105.0, -8.0, 108.9, -5.7)  # (minx, miny, maxx, maxy)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d17366f6aaca26e8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for file in filelist:\n",
    "    ds = xr.open_dataset(os.path.join(nc_dir,file), engine='netcdf4')\n",
    "    \n",
    "    # Original dimension\n",
    "    nrows = ds.sizes[\"Rows\"]   # atau \"row\"\n",
    "    ncols = ds.sizes[\"Columns\"] # atau \"column\"\n",
    "    \n",
    "    # metadata\n",
    "    lat_min = float(ds.geospatial_lat_min)\n",
    "    lat_max = float(ds.geospatial_lat_max)\n",
    "    lon_min = float(ds.geospatial_lon_min)\n",
    "    lon_max = float(ds.geospatial_lon_max)\n",
    "    \n",
    "    # generate grids coordinates\n",
    "    lats = np.linspace(lat_max, lat_min, nrows)   # north → south\n",
    "    lons = np.linspace(lon_min, lon_max, ncols)\n",
    "    \n",
    "    # Assign koordinat\n",
    "    ds = ds.assign_coords(\n",
    "        lat=(\"Rows\", lats),\n",
    "        lon=(\"Columns\", lons)\n",
    "    )\n",
    "    \n",
    "    # Ganti dimensi: row→lat, column→lon\n",
    "    ds = ds.swap_dims({\"Rows\": \"lat\", \"Columns\": \"lon\"})\n",
    "    \n",
    "    # Tambahkan atribut CF\n",
    "    ds[\"lat\"].attrs = {\n",
    "        \"standard_name\": \"latitude\",\n",
    "        \"long_name\": \"latitude\",\n",
    "        \"units\": \"degrees_north\"\n",
    "    }\n",
    "    ds[\"lon\"].attrs = {\n",
    "        \"standard_name\": \"longitude\",\n",
    "        \"long_name\": \"longitude\",\n",
    "        \"units\": \"degrees_east\"\n",
    "    }\n",
    "    \n",
    "    sliced = ds.sel(lat=slice(domain[3],domain[1]), lon=slice(domain[0],domain[2]))\n",
    "    sliced = sliced['RRQPE'].squeeze()\n",
    "    sliced = sliced.rio.write_crs(\"EPSG:4326\")\n",
    "    sliced = sliced.rio.set_spatial_dims(x_dim=\"lon\", y_dim=\"lat\", inplace=True)\n",
    "    \n",
    "    tif_dir = \"G:/SCAMPR/tif\"\n",
    "    time_indicator = file.split('_')[3]\n",
    "    tif_file = f\"{tif_dir}/rrqpe_jawa_{time_indicator}.tif\"\n",
    "    sliced.rio.to_raster(tif_file, compression='LZW', dtype='float32')\n",
    "    print(\"Saved:\", tif_file)\n",
    "    ds.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0a8c86be5a2a362"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Modify the script as needed to automate the data fetching and clipping for operational purpose"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a59c8afa895fedf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cc77b982d0bc31f4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
