{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Clip Basic Data (DEM, DDM, FAM)\n",
    "We use data from Hydrosheds with 3s resolution (approx 90m at the equator). The DEM already conditioned for hydrology (pit removed, sink filled, stream burned). The flow direction already in ESRI DDM, and flow accumulation also ready to use https://www.hydrosheds.org/hydrosheds-core-downloads. Here we need to clip the data to our area of interest and set the format to Float32"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f799b544400f9b29"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-07T08:35:17.857002800Z",
     "start_time": "2025-09-07T08:35:17.159735800Z"
    }
   },
   "outputs": [
    {
     "ename": "CPLE_AppDefinedError",
     "evalue": "Deleting soil_param_b_5km_global_jabar_float32.tif failed: Permission denied",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mCPLE_AppDefinedError\u001B[39m                      Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[22]\u001B[39m\u001B[32m, line 17\u001B[39m\n\u001B[32m     14\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m da_clipped\n\u001B[32m     16\u001B[39m extent = (\u001B[32m105.0\u001B[39m, -\u001B[32m8.0\u001B[39m, \u001B[32m108.9\u001B[39m, -\u001B[32m5.7\u001B[39m)   \u001B[38;5;66;03m# xmin, ymin, xmax, ymax\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m17\u001B[39m da = clip_raster(\n\u001B[32m     18\u001B[39m     src_raster=\u001B[33m\"\u001B[39m\u001B[33mD:/Data/EF5/soil_param_b_5km_global_corrected.tif\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     19\u001B[39m     dst_raster=\u001B[33m\"\u001B[39m\u001B[33msoil_param_b_5km_global_jabar_float32.tif\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     20\u001B[39m     extent=extent,\n\u001B[32m     21\u001B[39m )\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[22]\u001B[39m\u001B[32m, line 12\u001B[39m, in \u001B[36mclip_raster\u001B[39m\u001B[34m(src_raster, dst_raster, extent)\u001B[39m\n\u001B[32m      8\u001B[39m da_clipped = da.rio.clip_box(minx=xmin, miny=ymin, maxx=xmax, maxy=ymax)\n\u001B[32m     10\u001B[39m da_clipped = da_clipped.astype(\u001B[33m\"\u001B[39m\u001B[33mfloat32\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m12\u001B[39m da_clipped.rio.to_raster(dst_raster, compress=\u001B[33m\"\u001B[39m\u001B[33mLZW\u001B[39m\u001B[33m\"\u001B[39m, tiled=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m     14\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m da_clipped\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\geo-env\\Lib\\site-packages\\rioxarray\\raster_array.py:1181\u001B[39m, in \u001B[36mRasterArray.to_raster\u001B[39m\u001B[34m(self, raster_path, driver, dtype, tags, windowed, recalc_transform, lock, compute, **profile_kwargs)\u001B[39m\n\u001B[32m   1162\u001B[39m out_profile = {\n\u001B[32m   1163\u001B[39m     key: value\n\u001B[32m   1164\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m out_profile.items()\n\u001B[32m   (...)\u001B[39m\u001B[32m   1175\u001B[39m     )\n\u001B[32m   1176\u001B[39m }\n\u001B[32m   1177\u001B[39m rio_nodata = (\n\u001B[32m   1178\u001B[39m     \u001B[38;5;28mself\u001B[39m.encoded_nodata \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.encoded_nodata \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m.nodata\n\u001B[32m   1179\u001B[39m )\n\u001B[32m-> \u001B[39m\u001B[32m1181\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m RasterioWriter(raster_path=raster_path).to_raster(\n\u001B[32m   1182\u001B[39m     xarray_dataarray=\u001B[38;5;28mself\u001B[39m._obj,\n\u001B[32m   1183\u001B[39m     tags=tags,\n\u001B[32m   1184\u001B[39m     driver=driver,\n\u001B[32m   1185\u001B[39m     height=\u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mself\u001B[39m.height),\n\u001B[32m   1186\u001B[39m     width=\u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mself\u001B[39m.width),\n\u001B[32m   1187\u001B[39m     count=\u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mself\u001B[39m.count),\n\u001B[32m   1188\u001B[39m     dtype=dtype,\n\u001B[32m   1189\u001B[39m     crs=\u001B[38;5;28mself\u001B[39m.crs,\n\u001B[32m   1190\u001B[39m     transform=\u001B[38;5;28mself\u001B[39m.transform(recalc=recalc_transform),\n\u001B[32m   1191\u001B[39m     gcps=\u001B[38;5;28mself\u001B[39m.get_gcps(),\n\u001B[32m   1192\u001B[39m     nodata=rio_nodata,\n\u001B[32m   1193\u001B[39m     windowed=windowed,\n\u001B[32m   1194\u001B[39m     lock=lock,\n\u001B[32m   1195\u001B[39m     compute=compute,\n\u001B[32m   1196\u001B[39m     **out_profile,\n\u001B[32m   1197\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\geo-env\\Lib\\site-packages\\rioxarray\\raster_writer.py:286\u001B[39m, in \u001B[36mRasterioWriter.to_raster\u001B[39m\u001B[34m(self, xarray_dataarray, tags, windowed, lock, compute, **kwargs)\u001B[39m\n\u001B[32m    278\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m kwargs[\u001B[33m\"\u001B[39m\u001B[33mnodata\u001B[39m\u001B[33m\"\u001B[39m] \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    279\u001B[39m     \u001B[38;5;66;03m# Ensure dtype of output data matches the expected dtype.\u001B[39;00m\n\u001B[32m    280\u001B[39m     \u001B[38;5;66;03m# This check is added here as the dtype of the data is\u001B[39;00m\n\u001B[32m    281\u001B[39m     \u001B[38;5;66;03m# converted right before writing.\u001B[39;00m\n\u001B[32m    282\u001B[39m     kwargs[\u001B[33m\"\u001B[39m\u001B[33mnodata\u001B[39m\u001B[33m\"\u001B[39m] = _ensure_nodata_dtype(\n\u001B[32m    283\u001B[39m         original_nodata=kwargs[\u001B[33m\"\u001B[39m\u001B[33mnodata\u001B[39m\u001B[33m\"\u001B[39m], new_dtype=numpy_dtype\n\u001B[32m    284\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m286\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m rasterio.open(\u001B[38;5;28mself\u001B[39m.raster_path, \u001B[33m\"\u001B[39m\u001B[33mw\u001B[39m\u001B[33m\"\u001B[39m, **kwargs) \u001B[38;5;28;01mas\u001B[39;00m rds:\n\u001B[32m    287\u001B[39m     _write_metatata_to_raster(\n\u001B[32m    288\u001B[39m         raster_handle=rds, xarray_dataset=xarray_dataarray, tags=tags\n\u001B[32m    289\u001B[39m     )\n\u001B[32m    290\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (lock \u001B[38;5;129;01mand\u001B[39;00m is_dask_collection(xarray_dataarray.data)):\n\u001B[32m    291\u001B[39m         \u001B[38;5;66;03m# write data to raster immmediately if not dask array\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\geo-env\\Lib\\site-packages\\rasterio\\env.py:463\u001B[39m, in \u001B[36mensure_env_with_credentials.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwds)\u001B[39m\n\u001B[32m    460\u001B[39m     session = DummySession()\n\u001B[32m    462\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m env_ctor(session=session):\n\u001B[32m--> \u001B[39m\u001B[32m463\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m f(*args, **kwds)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\geo-env\\Lib\\site-packages\\rasterio\\__init__.py:366\u001B[39m, in \u001B[36mopen\u001B[39m\u001B[34m(fp, mode, driver, width, height, count, crs, transform, dtype, nodata, sharing, opener, **kwargs)\u001B[39m\n\u001B[32m    364\u001B[39m writer = get_writer_for_driver(driver)\n\u001B[32m    365\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m writer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m366\u001B[39m     dataset = writer(\n\u001B[32m    367\u001B[39m         path,\n\u001B[32m    368\u001B[39m         mode,\n\u001B[32m    369\u001B[39m         driver=driver,\n\u001B[32m    370\u001B[39m         width=width,\n\u001B[32m    371\u001B[39m         height=height,\n\u001B[32m    372\u001B[39m         count=count,\n\u001B[32m    373\u001B[39m         crs=crs,\n\u001B[32m    374\u001B[39m         transform=transform,\n\u001B[32m    375\u001B[39m         dtype=dtype,\n\u001B[32m    376\u001B[39m         nodata=nodata,\n\u001B[32m    377\u001B[39m         sharing=sharing,\n\u001B[32m    378\u001B[39m         **kwargs\n\u001B[32m    379\u001B[39m     )\n\u001B[32m    380\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    381\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m DriverCapabilityError(\n\u001B[32m    382\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mWriter does not exist for driver: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m\"\u001B[39m % \u001B[38;5;28mstr\u001B[39m(driver)\n\u001B[32m    383\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mrasterio\\\\_io.pyx:1509\u001B[39m, in \u001B[36mrasterio._io.DatasetWriterBase.__init__\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mrasterio\\\\_io.pyx:322\u001B[39m, in \u001B[36mrasterio._io._delete_dataset_if_exists\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mrasterio\\\\_err.pyx:289\u001B[39m, in \u001B[36mrasterio._err.exc_wrap_int\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[31mCPLE_AppDefinedError\u001B[39m: Deleting soil_param_b_5km_global_jabar_float32.tif failed: Permission denied"
     ]
    }
   ],
   "source": [
    "import rioxarray\n",
    "import numpy as np\n",
    "\n",
    "def clip_raster(src_raster, dst_raster, extent):\n",
    "    da = rioxarray.open_rasterio(src_raster, masked=False).squeeze()\n",
    "\n",
    "    xmin, ymin, xmax, ymax = extent\n",
    "    da_clipped = da.rio.clip_box(minx=xmin, miny=ymin, maxx=xmax, maxy=ymax)\n",
    "\n",
    "    da_clipped = da_clipped.astype(\"float32\")\n",
    "\n",
    "    da_clipped.rio.to_raster(dst_raster, compress=\"LZW\", tiled=False)\n",
    "    \n",
    "    return da_clipped\n",
    "\n",
    "extent = (105.0, -8.0, 108.9, -5.7)   # xmin, ymin, xmax, ymax\n",
    "da = clip_raster(\n",
    "    src_raster=\"D:/Data/EF5/soil_param_b_5km_global_corrected.tif\",\n",
    "    dst_raster=\"soil_param_b_5km_global_jabar_float32.tif\",\n",
    "    extent=extent,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Align CREST grid parameters\n",
    "\n",
    "EF5 requires the gridded CREST parameter to be at the exact same grid resolution and extent as the DEM. Hence, we need to regrid the parameters and clip them to the same extent as the DEM. First, some parameter grid is off by several degrees to southwest (you need to check on QGIS for this), we will fix that by adjusting the data."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70a587b6af9a6ed0"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil disimpan ke D:/Data/EF5/soil_param_b_5km_global_corrected.tif\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "from rasterio.enums import Resampling\n",
    "\n",
    "# === Parameter shift (dalam jumlah pixel) ===\n",
    "row_shift = -4   # negative = shift north, positive = shift south\n",
    "col_shift = 23   # negative = shift west, positive = shift east\n",
    "\n",
    "# === Input/Output ===\n",
    "input_file = \"D:/Data/EF5/soil_param_b_5km_global.tif\"      # shifted raster\n",
    "output_file = \"D:/Data/EF5/soil_param_b_5km_global_corrected.tif\"\n",
    "\n",
    "# === Baca raster input ===\n",
    "with rasterio.open(input_file) as src:\n",
    "    profile = src.profile\n",
    "    data = src.read(1)\n",
    "    nodata = src.nodata if src.nodata is not None else -9999\n",
    "\n",
    "# === Geser array ===\n",
    "corrected = np.full_like(data, nodata)  # isi awal dengan nodata\n",
    "\n",
    "nrows, ncols = data.shape\n",
    "\n",
    "# Hitung indeks sumber dan target\n",
    "row_idx_src = np.arange(nrows)\n",
    "col_idx_src = np.arange(ncols)\n",
    "\n",
    "row_idx_tgt = row_idx_src + row_shift\n",
    "col_idx_tgt = col_idx_src + col_shift\n",
    "\n",
    "# Filter supaya tetap dalam batas array\n",
    "valid_rows = (row_idx_tgt >= 0) & (row_idx_tgt < nrows)\n",
    "valid_cols = (col_idx_tgt >= 0) & (col_idx_tgt < ncols)\n",
    "\n",
    "# Copy isi pixel\n",
    "for i_src, i_tgt in zip(row_idx_src[valid_rows], row_idx_tgt[valid_rows]):\n",
    "    for j_src, j_tgt in zip(col_idx_src[valid_cols], col_idx_tgt[valid_cols]):\n",
    "        corrected[i_tgt, j_tgt] = data[i_src, j_src]\n",
    "\n",
    "# === Simpan hasil ===\n",
    "profile.update(dtype=rasterio.float32, compress=\"DEFLATE\", nodata=nodata)\n",
    "\n",
    "with rasterio.open(output_file, \"w\", **profile) as dst:\n",
    "    dst.write(corrected.astype(np.float32), 1)\n",
    "\n",
    "print(f\"Hasil disimpan ke {output_file}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-07T08:21:03.851633300Z",
     "start_time": "2025-09-07T08:20:50.319003500Z"
    }
   },
   "id": "a31b24c9ff330156"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can align the grid using xarray interpolation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6119deb7e1b47ec2"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import rioxarray"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-07T08:25:02.301072700Z",
     "start_time": "2025-09-07T08:25:02.272854200Z"
    }
   },
   "id": "fd3f448154c1d097"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "dem_file = \"dem_clipped_jabar_float32.tif\"\n",
    "param_file = \"D:/Data/EF5/soil_param_corrected/soil_param_wm_5km_global_corrected_jabar.tif\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-07T16:14:30.198580600Z",
     "start_time": "2025-09-07T16:14:30.169283900Z"
    }
   },
   "id": "f66fb488a80fa158"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "da_dem = rioxarray.open_rasterio(dem_file, masked=True).squeeze()\n",
    "da_input = rioxarray.open_rasterio(param_file, masked=True).squeeze()\n",
    "dem_lats = da_dem.y.values\n",
    "dem_lons = da_dem.x.values\n",
    "\n",
    "#interpolate using 'nearest' method\n",
    "da_interp = da_input.interp(x=dem_lons, y=dem_lats, method=\"nearest\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-07T16:14:31.197271Z",
     "start_time": "2025-09-07T16:14:31.137848300Z"
    }
   },
   "id": "825aba212db0c308"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "da_interp.rio.to_raster(\n",
    "    \"D:/Projects/ef5-preprocessing/data/parameters/CREST/soil_param_wm_5km_global_corrected_jabar.tif\",\n",
    "    compress=\"LZW\",\n",
    "    tiled=False,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-07T16:14:42.707698200Z",
     "start_time": "2025-09-07T16:14:42.390781400Z"
    }
   },
   "id": "7c0e3b9b895015ed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Automate Gauge Placement\n",
    "Gauge in EF5 can be a virtual or real gauge. In this case we will place virtual gauge based on administration boundaries. We use the admin boundary and flow accumulation data. The idea is to place gauge on the highest flow accumulation pixel in an admin boundary."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e52e0864356a2d29"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import rioxarray\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T06:27:51.987681400Z",
     "start_time": "2025-09-09T06:27:51.958070200Z"
    }
   },
   "id": "c9c5c35426d79ab9"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#Flow Accumulation Data\n",
    "fam = rioxarray.open_rasterio(\"D:/Projects/ef5-preprocessing/data/basic/fam_clipped_jabar_float32.tif\", masked=True).squeeze()\n",
    "\n",
    "#Administration boundary data\n",
    "kel = gpd.read_file(\"D:/Data/geojson_kelurahan/31/kelurahan_jakarta_all.geojson\")\n",
    "kel = kel.to_crs(\"EPSG:4326\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T06:23:39.540057200Z",
     "start_time": "2025-09-09T06:23:38.594359500Z"
    }
   },
   "id": "7de22014f2430d0"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "#Empty dictionary to hold extracted data\n",
    "data = {\n",
    "    'name':[],\n",
    "    'fam':[],\n",
    "    'lon':[],\n",
    "    'lat':[],\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T06:24:26.049800Z",
     "start_time": "2025-09-09T06:24:26.004688900Z"
    }
   },
   "id": "50ec5b3f9b67c232"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Pulau Kelapa: No data found in bounds.\n",
      "Error processing Pulau Harapan: No data found in bounds.\n"
     ]
    }
   ],
   "source": [
    "#Iterate through all geodataframe\n",
    "for i, row in kel.iterrows():\n",
    "    name = row['NAMOBJ']\n",
    "    geom = row['geometry']\n",
    "    try:\n",
    "        #clip flow accumulation based on boundary\n",
    "        fam_clip = fam.rio.clip([geom], kel.crs, drop=True, all_touched=False)\n",
    "        #looking for maximum fam value\n",
    "        argmax_flat = fam_clip.argmax().item()   # posisi linear\n",
    "        y_ind, x_ind = np.unravel_index(argmax_flat, fam_clip.shape)\n",
    "    \n",
    "        # convert from index to coordinate\n",
    "        lon = fam_clip[\"x\"].values[x_ind]\n",
    "        lat = fam_clip[\"y\"].values[y_ind]\n",
    "    \n",
    "        data['name'].append(name)\n",
    "        data['fam'].append(fam_clip.max().item())\n",
    "        data['lon'].append(lon)\n",
    "        data['lat'].append(lat)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {name}: {e}\")\n",
    "        data['name'].append(name)\n",
    "        data['fam'].append(None)\n",
    "        data['lon'].append(None)\n",
    "        data['lat'].append(None)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T06:28:50.990039400Z",
     "start_time": "2025-09-09T06:27:54.255797800Z"
    }
   },
   "id": "e1e0328d1ef48cb5"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "#transform into geodataframe and save to geojson\n",
    "gdf = gpd.GeoDataFrame(data, geometry=gpd.points_from_xy(data['lon'], data['lat']), crs=\"EPSG:4326\")\n",
    "gdf = gdf.dropna(how='any', subset=['lon', 'lat'])\n",
    "gdf.to_file(\"gauge_potential_jakarta.geojson\", driver='GeoJSON')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T06:29:20.314430500Z",
     "start_time": "2025-09-09T06:29:20.272693800Z"
    }
   },
   "id": "f79c066219b00c74"
  },
  {
   "cell_type": "markdown",
   "source": [
    "You need to validate the location later in QGIS to make sure the gauge is correctly placed in the \"river\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8d60476d4e787525"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate Gauge and Basin\n",
    "This part is just to automate the generation of \"GAUGE\" and \"BASIN\" part, you need to copy and paste the output to the original control file."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "94f4b08b09af0ba3"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Konversi selesai, disimpan di gauges_jakarta.ini\n"
     ]
    }
   ],
   "source": [
    "# Konversi gauge location to config\n",
    "import json\n",
    "\n",
    "# --- Muat GeoJSON ---\n",
    "with open(\"gauge_potential_jakarta.geojson\") as f:\n",
    "    geojson = json.load(f)\n",
    "\n",
    "output_file = \"gauges_jakarta.ini\"\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    for feature in geojson[\"features\"]:\n",
    "        name = feature[\"properties\"][\"name\"]\n",
    "        lon, lat = feature[\"geometry\"][\"coordinates\"]\n",
    "        f.write(f\"[Gauge {name.replace(' ','')}]\\n\")\n",
    "        f.write(f\"LON={lon}\\n\")\n",
    "        f.write(f\"LAT={lat}\\n\\n\")\n",
    "    \n",
    "    f.write(\"[Basin Jakarta]\\n\")\n",
    "    for feature in geojson[\"features\"]:\n",
    "        name = feature[\"properties\"][\"name\"]\n",
    "        f.write(f\"GAUGE={name.replace(' ','')}\\n\")\n",
    "        \n",
    "\n",
    "print(f\"Konversi selesai, disimpan di {output_file}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-09T08:25:48.771116Z",
     "start_time": "2025-09-09T08:25:48.698058100Z"
    }
   },
   "id": "72658120a62b538c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c01fa1541cde14b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
